{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ed8dd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this notebook I want to investigate the technique of \"phase mapping\" (working name)\n",
    "\n",
    "#Phase mapping takes the idea of the (Feynman) Path integral and tries to apply it to noisy data (intended for statistical noise); it can perhaps be seen as a method of error mitigation or as a method to improve the signal2noise ratio\n",
    "\n",
    "\n",
    "#The main idea is the following: The big difference between noise and our signal is that the signal is a stable source of counts,\n",
    "#while noise should create counts in a more statistica√∂ way\n",
    "\n",
    "#Therefore the count yield of the noise is fluctuating\n",
    "\n",
    "\n",
    "#In most physics experiments, the advantage of averaging is that stochastic noise can cancel itself bc it goes into both \"directions\" (negative and positive)\n",
    "\n",
    "#In the case of count distributions though, it is always positive: it always adds up\n",
    "#So we need a method that can make noisy signals cancel each other\n",
    "#In nature, this is achieved by the path integral\n",
    "\n",
    "#The idea that each possible realization of systems in nature has an Amplitude which is directly linked to its probability\n",
    "#The amplitude is (more or less) given by the path integral A=\\int e^{iS/\\hbar}\n",
    "#We see a phase factor with iS/\\hbar as exponent\n",
    "\n",
    "#This phase factor results in the action S being effectively minimized in nature\n",
    "#the scale against which S is measured (\\hbar) is the smalled sensible unit of action and incredibly small\n",
    "#meaning on paths, for which S is not minimal, the phase factor will take all possible phases. Adding them up results in destructive interference\n",
    "#For a stable path (meaning local extreme point, e.g. minimum), S is not fluctuating in first order. The phase factor will be roughly (or close to) one, resulting in constructive interference\n",
    "\n",
    "\n",
    "#We want to apply this technique to our signal now\n",
    "#We run a given circuit many times with a stochastic noise model\n",
    "\n",
    "#the noisy part of the outcome will vary, while the signal will stay stable\n",
    "#by making all outcomes interfere according to their fluctuations, we will weaken fluctuating signals and amplify stable signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d9ee485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import *\n",
    "import numpy as np\n",
    "from qiskit.providers.aer.noise import NoiseModel\n",
    "from qiskit.providers.aer.noise.errors import pauli_error, depolarizing_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "69ab54f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will run a 3 Qubit GHZ state as test\n",
    "qc = QuantumCircuit(3)\n",
    "qc.h(0)\n",
    "qc.cx(0,[1,2])\n",
    "\n",
    "qc.measure_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "95235af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we can change the sensitivity of the method\n",
    "#it makes sense keeping it as 1 right now, but after having gone through the nb, one can play a bit with it, e.g. trying sensitivity=2\n",
    "\n",
    "#I have already played a little bit with this parameter and choosing it bigger can actually yield a much better result\n",
    "sensitivity=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ecff1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose our simulator\n",
    "sim = Aer.get_backend(\"aer_simulator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "78cf5a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the perfect result in this case is\n",
    "perfect_result={\"000\": 0.5,\n",
    "               \"111\": 0.5\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0d0eb104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next, we need our stochastic noise model\n",
    "\n",
    "def get_noise(p_meas,p_gate):\n",
    "    error_meas = pauli_error([('X',p_meas), ('I', 1 - p_meas)])\n",
    "    error_gate1 = depolarizing_error(p_gate, 1)\n",
    "    error_gate2 = error_gate1.tensor(error_gate1)\n",
    "\n",
    "    noise_model = NoiseModel()\n",
    "    noise_model.add_all_qubit_quantum_error(error_meas, \"measure\") # measurement error is applied to measurements\n",
    "    noise_model.add_all_qubit_quantum_error(error_gate1, [\"h\"]) # single qubit gate error is applied to x gates\n",
    "    noise_model.add_all_qubit_quantum_error(error_gate2, [\"cx\"]) # two qubit gate error is applied to cx gates\n",
    "        \n",
    "    return noise_model\n",
    "\n",
    "\n",
    "noise_model=get_noise(0.05,0.05)\n",
    "#5 percent probability for each error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "18ec0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare circuit for running\n",
    "trans_qc=transpile(qc,sim)\n",
    "qobj=assemble(trans_qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1fb1f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run qc multiple times\n",
    "dictionary_list=[]\n",
    "for i in range(100):\n",
    "    dictionary_list.append(sim.run(qobj, noise_model=noise_model).result().get_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fe4829c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the mean fidelities of each of the outcomes\n",
    "from qiskit.quantum_info import hellinger_fidelity\n",
    "fid=[]\n",
    "for dictionary in dictionary_list:\n",
    "    fid.append(hellinger_fidelity(dictionary,perfect_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "74d328c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the mean fidelity is given by 0.7803690511085715\n"
     ]
    }
   ],
   "source": [
    "#look at the mean fidelity\n",
    "print(f\" the mean fidelity is given by {np.mean(fid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "787f63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dictionary with relative mean counts for each outcome  (these will serve as reference scales for exponentials)\n",
    "key_list=dictionary_list[0].keys()\n",
    "\n",
    "\n",
    "#get mean values\n",
    "mean_fid={}\n",
    "for key in key_list:\n",
    "    mean_fid[key]=0\n",
    "    \n",
    "    \n",
    "#fill up the array\n",
    "for dictionary in dictionary_list:\n",
    "    for key in dictionary:\n",
    "        mean_fid[key]+=dictionary[key]\n",
    "for key in mean_fid:\n",
    "    mean_fid[key]/=len(dictionary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ee178c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now apply the phase mapping technique (apply the phase weights to each outcome of each single measurement)\n",
    "\n",
    "total_dict_phase={}\n",
    "for key in key_list:\n",
    "    total_dict_phase[key]=0\n",
    "\n",
    "for dictionary in dictionary_list:\n",
    "    for key in total_dict_phase:\n",
    "        if key in dictionary:\n",
    "            total_dict_phase[key]+=dictionary[key]*np.exp(1j*2*np.pi*dictionary[key]*sensitivity/mean_fid[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cf2fc6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'000': (38702.0997317676+382.5468657027069j), '111': (39033.06473349433+298.0774513569704j), '101': (2895.219552036939+319.6503186522453j), '110': (2024.157983882905+265.94268376523195j), '010': (2741.3587166036327+304.50039043258994j), '011': (2077.3966503310953+303.1282113547756j), '001': (1625.133520763893+238.2923831371981j), '100': (1885.646788291754+272.2216329522528j)}\n"
     ]
    }
   ],
   "source": [
    "#look at dictionary before we take absolute values\n",
    "print(total_dict_phase)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9b391118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for an actual result, we take the absolute value of each outcome in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "95baa61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in total_dict_phase:\n",
    "    total_dict_phase[key]=np.abs(total_dict_phase[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "703048a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85334415506561\n"
     ]
    }
   ],
   "source": [
    "#we look at fidelity of our distribution obtained by apply the phase mapping procedure\n",
    "fid_ph1=hellinger_fidelity(total_dict_phase,perfect_result)\n",
    "print(fid_ph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5125998b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " complex Amplitudes are {'000': (97.10459890515628+0.05259988014798969j), '111': (97.40500788175277-0.07252715257588993j), '101': (67.71930602433719-1.212866882619275j), '110': (60.51041111650118-2.1728330397684j), '010': (63.59180291276981-2.2432443194216862j), '011': (59.382081729350254-1.0581578181047095j), '001': (49.809581479517675-4.0553170389813475j), '100': (54.262969273456775-2.8813814107050026j)}\n",
      "absolute values of Amplitudes are {'000': 97.10461315137746, '111': 97.40503488337849, '101': 67.7301665027688, '110': 60.54941004590135, '010': 63.63135660013211, '011': 59.39150889209037, '001': 49.97439347757371, '100': 54.339416570350394}\n"
     ]
    }
   ],
   "source": [
    "#what we have done was to sum up our counts/results for each outcome weighted by a phase factor\n",
    "\n",
    "#another idea had was to sum up the phase factors directly and multiply the outcomes of an averaged outcome dictionary by the respective aplitudes\n",
    "\n",
    "Amplitudes={}\n",
    "\n",
    "for key in key_list:\n",
    "    Amplitudes[key]=0\n",
    "\n",
    "\n",
    "for key in Amplitudes:\n",
    "    for i in range(len(dictionary_list)):\n",
    "        if key in dictionary_list[i].keys():\n",
    "            Amplitudes[key]+=np.exp(1j*2*np.pi*dictionary_list[i][key]/(mean_fid[key]))\n",
    "print(f\" complex Amplitudes are {Amplitudes}\")\n",
    "\n",
    "#take the absolute values of each entry of Amplitudes\n",
    "for key in Amplitudes:\n",
    "    Amplitudes[key]=np.abs(Amplitudes[key])\n",
    "    \n",
    "print(f\"absolute values of Amplitudes are {Amplitudes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d182235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next we obtain the total averaged outcome dictionary\n",
    "dict_total={}\n",
    "for key in key_list:\n",
    "    dict_total[key]=0\n",
    "#add up all the result\n",
    "for dictionary in dictionary_list:\n",
    "    for key in dictionary:\n",
    "        dict_total[key]+=dictionary[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "af220447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we multiply the entries by our respective amplitudes\n",
    "\n",
    "for key in dict_total:\n",
    "    dict_total[key]*=Amplitudes[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d2b26232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8526801535932208\n"
     ]
    }
   ],
   "source": [
    "#check the fidelity\n",
    "fid_ph2=hellinger_fidelity(perfect_result,dict_total)\n",
    "print(fid_ph2)\n",
    "\n",
    "#the fidelity in this case is also better than of the single measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "49cd85bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have seen that we can improve the fidelity of our measurements by using a superposition of different mappings\n",
    "#weighted by local phases (local meaning the phase depends on the outcome)\n",
    "\n",
    "#this achieves that noisy outcomes get suppressed (as can be seen by the Amplitude dictionary)\n",
    "#effectively, we improve the signal to noise ratio\n",
    "\n",
    "#we could optimize this surely in many ways. One possibility that I can directly think of would be to try different reference scales in the complex exponential, \n",
    "#so that we actually get proper destructive interference for the noise\n",
    "#by choosing our reference scale smaller, we make the method more sensitive towards noise (thus more unstable but potentially more effective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "167ba447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average fidelity by single circuit runs is 0.7803690511085715\n",
      "the best fidelity by single cirucit runs is 0.8065223797608921\n"
     ]
    }
   ],
   "source": [
    "#again, to compare the numbers:\n",
    "print(f\"the average fidelity by single circuit runs is {np.mean(fid)}\")\n",
    "print(f\"the best fidelity by single cirucit runs is {fid[np.argmax(fid)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "509acbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the fidelities using the phase mapping technique are 0.85334415506561 and 0.8526801535932208\n"
     ]
    }
   ],
   "source": [
    "print(f\"the fidelities using the phase mapping technique are {fid_ph1} and {fid_ph2}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c41460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one can further explore the effects of choosing different reference scales, e.g. trying 0.5*mean_fid instead of mean_fid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
